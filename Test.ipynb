{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) with Pegasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important namespaces are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical operation\n",
    "import pandas as pd #tabular data\n",
    "from tqdm import tqdm #progress bars\n",
    "import matplotlib.pyplot as plt #figures\n",
    "from sklearn.linear_model import LinearRegression #linear regression benchmark\n",
    "import sys #System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custum modules, consisting of among others the Pegasos algorithm, are imported. \n",
    "Therefore, a relative path is appended to the system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'Modules/')\n",
    "from Evaluation_Metric import Metric_regression\n",
    "from Cross_validation import preparation_cross_validation\n",
    "golden_section_search = __import__('20220716_Golden_Section_Search').golden_section_search\n",
    "from Primal_Pegasos import Pegasos_regression\n",
    "Pegasos_kernel = __import__('Kernel_Pegasos').Pegasos_kernel_regression\n",
    "Kernel = __import__('Kernel_Pegasos').Kernel_polynomial   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **boston house prices** dataset is imported. \n",
    "The dataset is commonly used for comparison regression algorithm.\n",
    "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.\n",
    "\n",
    "http://lib.stat.cmu.edu/datasets/boston (accessed on 26th July 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non numeric values are removed from this dataset. \n",
    "Each row, containing NaN, is removed ensuring only numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan = np.isnan(data)\n",
    "X_nan = X_nan.sum(axis=1)\n",
    "X_no_nan = X_nan == 0\n",
    "X = data[X_no_nan,:]\n",
    "y = target[X_no_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix is centered around 0 with a standard deviation of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X - X.mean(axis=0)\n",
    "X = X / X.var(axis=0)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is randomly splitted in trainings and testing data. \n",
    "The algorthm is trained and the hyperparameter are adjusted based on the trainings data. \n",
    "The final performance evaluation is done with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = X.shape[0]\n",
    "split_fraction = 0.8\n",
    "n_random = np.random.permutation(n)\n",
    "n_train = n_random[:int(n*split_fraction)]\n",
    "n_test = n_random[int(n*split_fraction):]\n",
    "\n",
    "X_train = X[n_train,:]\n",
    "y_train = y[n_train]\n",
    "\n",
    "X_test = X[n_test,:]\n",
    "y_test =  y[n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainings data set is splitted into $n$ bags. \n",
    "For randomization the modul numpy is applied. \n",
    "The optimal regularisation parameter $\\lambda$ is searched such that the validation error is minimized. \n",
    "Therefore, the models are fitted on $n - 1$ bags and the performance is evaluated on $1$ bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bags = 10\n",
    "np.random.seed(42)\n",
    "bags_list = preparation_cross_validation(X_train, y_train, n_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is approximated with the validaiton error. \n",
    "Therefore, the function *MSE_l* fits the linear Pegasos models to the trainings data and return the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_opt_list = []\n",
    "epoch_max_diagram = 5\n",
    "def MSE_l (l, Pegasos_regression, epoch_max, epsilon, X_train, y_train, X_val, y_val):\n",
    "    Pegasos = Pegasos_regression(regularization=l,\n",
    "                                 epoch_max=epoch_max,\n",
    "                                 epsilon=epsilon,\n",
    "                                 verbose=False)\n",
    "    Pegasos.fit(X_train, y_train)\n",
    "    MSE_ = Pegasos.MSE(X_val, y_val)\n",
    "    return (MSE_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on the validation set is unimodal with exactly one minimum. \n",
    "The $n$ cross validation sets are plotted as a function of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:43<00:00,  4.39s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend_list = ['$n\\mathrm{_{bag}}$ = ' + str(i+1) for i in range(n_bags)]\n",
    "l_array = np.logspace(-5, 2, 100)\n",
    "for n_val in tqdm(range (n_bags)):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_min = lambda l: MSE_l(l, \n",
    "                              Pegasos_regression=Pegasos_regression, \n",
    "                              epoch_max=epoch_max_diagram, \n",
    "                              epsilon=1E-8, \n",
    "                              X_train=X_train_, \n",
    "                              y_train=y_train_, \n",
    "                              X_val=X_val_, \n",
    "                              y_val=y_val_)\n",
    "    MSE_min_vec = np.vectorize(MSE_min)\n",
    "    plt.plot(l_array, MSE_min_vec(l_array))\n",
    "\n",
    "plt.title('Epoch$\\mathrm{_{max}}$ = ' + '{:.0f}'.format(epoch_max_diagram))\n",
    "plt.xlabel('$\\lambda$ / -')\n",
    "plt.xscale('log')\n",
    "plt.xlim(1E-5, 10000)\n",
    "plt.ylabel('MEDV$\\mathrm{_{val}}$')\n",
    "plt.legend(legend_list, loc='upper right', fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optima $\\lambda$ are found with the golden section search. \n",
    "The golden section search finds the mimimum in a given intervall, for strictly unimodal functions. \n",
    "Thereafter, the whole trainings set is fitted with the average $\\lambda$ of the cross validation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (on validation set 1/10) = 15 | lambda = 0.012\n",
      "MSE (on validation set 2/10) = 43 | lambda = 0.0083\n",
      "MSE (on validation set 3/10) = 12 | lambda = 0.013\n",
      "MSE (on validation set 4/10) = 19 | lambda = 0.032\n",
      "MSE (on validation set 5/10) = 20 | lambda = 0.032\n",
      "MSE (on validation set 6/10) = 25 | lambda = 0.025\n",
      "MSE (on validation set 7/10) = 35 | lambda = 0.025\n",
      "MSE (on validation set 8/10) = 18 | lambda = 0.0056\n",
      "MSE (on validation set 9/10) = 64 | lambda = 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 92.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (on validation set 10/10) = 20 | lambda = 0.017\n",
      "Mean MSE Cross Validation = 27 +- 16.1\n",
      "Best lambda = 0.0188 +- 0.00941\n",
      "##########\n",
      "Regularizaion: 0.018838652510972918\n",
      "Max epoch: 5\n",
      "Primal Pegasos Linear\n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_max = 5\n",
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "l_opt_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_min = lambda l: MSE_l(l, \n",
    "                              Pegasos_regression=Pegasos_regression,\n",
    "                              epoch_max=epoch_max, \n",
    "                              epsilon=1E-8, \n",
    "                              X_train=X_train_, y_train=y_train_, \n",
    "                              X_val=X_val_, y_val=y_val_)\n",
    "    \n",
    "    l_opt = golden_section_search(MSE_min, 1E-3, 10, 1E-3)\n",
    "    l_opt_list.append(l_opt)\n",
    "    MSE_list.append(MSE_min(l_opt))\n",
    "    MSE_mean += MSE_min(l_opt) / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2g} | lambda = {:.2g}'.format(n_val+1, n_bags, MSE_min(l_opt), l_opt))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_opt_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best_linear = best_l_array.mean()\n",
    "Pegasos_linear_CV = Pegasos_regression(regularization=l_best_linear,\n",
    "                             epoch_max=epoch_max,\n",
    "                             epsilon=1E-8)\n",
    "Pegasos_linear_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is approximated with the validaiton error. \n",
    "Therefore, the function *MSE_kernel* fits the kernalized Pegasos models to the trainings data and return the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_kernel (l, Pegasos, Kernel, epoch_max, epsilon, X_train, y_train, X_val, y_val):\n",
    "    Pegasos_ = Pegasos(kernel=Kernel,\n",
    "                              regularization=l,\n",
    "                              epoch_max=epoch_max,\n",
    "                              epsilon=epsilon,\n",
    "                              verbose=False)\n",
    "    Pegasos_.fit(X_train, y_train)\n",
    "    MSE_ = Pegasos_.MSE(X_val, y_val)\n",
    "    return (MSE_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal $\\lambda$ are found for the linear kernalized Pegasos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (on validation set 1/10) = 15.68 | lambda = 0.016\n"
     ]
    }
   ],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "Kernel_linear = Kernel(c=0, p=1)\n",
    "l_opt_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_kernel_lambda = lambda l: MSE_kernel(l,\n",
    "                                             Pegasos=Pegasos_kernel, \n",
    "                                             Kernel=Kernel_linear,  \n",
    "                                             epoch_max=epoch_max, \n",
    "                                             epsilon=1E-8, \n",
    "                                             X_train=X_train_, \n",
    "                                             y_train=y_train_, \n",
    "                                             X_val=X_val_, \n",
    "                                             y_val=y_val_)\n",
    "    \n",
    "    l_opt = golden_section_search(MSE_kernel_lambda, 1E-5, 100, 1E-3)\n",
    "    l_opt_list.append(l_opt)\n",
    "    MSE_list.append(MSE_min(l_opt))\n",
    "    MSE_mean += MSE_min(l_opt) / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | lambda = {:.2g}'.format(n_val+1, n_bags, MSE_min(l_opt), l_opt))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_opt_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "Pegasos_kernel_linear_CV = Pegasos_kernel(kernel=Kernel_linear,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_linear_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal $c$ and $\\lambda$ are aproximated with the grid search. \n",
    "Higher $c$ gives more weight to the features with lower dimensions. \n",
    "Thus, $c$ and $\\lambda$ are reducing the complexity of the model.\n",
    "\n",
    "First, order of magnitude of the parameter $c$ and $\\lambda$ is searched. Thereafter, the search repeated with smaller step sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "c_best_list = []\n",
    "l_best_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "\n",
    "    best_val = 1E8\n",
    "    best_l = 0\n",
    "    best_c = 0\n",
    "    for c in [0, 1, 10, 100]:\n",
    "        Kernel_2 = Kernel(c=c, p=2)\n",
    "        for l in [1E-5, 1E-4, 1E-3, 1E-2, 0.1, 1, 10]:\n",
    "            Pegasos_reg_kernel_2 = Pegasos_kernel(kernel=Kernel_2, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_2.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_2 = Pegasos_reg_kernel_2.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_2 = Pegasos_reg_kernel_2.MSE(X_val_, y_val_)\n",
    "            #print('Train:', MSE_Pegasos_train_2)\n",
    "            #print('Val:', MSE_Pegasos_val_2)\n",
    "            if MSE_Pegasos_val_2 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_2        \n",
    "                best_c = c\n",
    "                \n",
    "    c_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    l_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    for c in c_search:\n",
    "        Kernel_2 = Kernel(c=c, p=2)\n",
    "        for l in l_search:\n",
    "            Pegasos_reg_kernel_2 = Pegasos_kernel(kernel=Kernel_2, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_2.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_2 = Pegasos_reg_kernel_2.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_2 = Pegasos_reg_kernel_2.MSE(X_val_, y_val_)\n",
    "            #print('Train:', MSE_Pegasos_train_2)\n",
    "            #print('Val:', MSE_Pegasos_val_2)\n",
    "            if MSE_Pegasos_val_2 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_2        \n",
    "                best_c = c\n",
    "    \n",
    "    c_best_list.append(best_c)\n",
    "    l_best_list.append(best_l)\n",
    "    MSE_list.append(MSE_min(l_opt))\n",
    "\n",
    "    MSE_mean += best_val / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | c = {} | lambda = {:.2g}'.format(n_val+1, n_bags, best_val, best_c, best_l))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_best_list)\n",
    "c_best_array = np.array(c_best_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "print('Best c = {:.3g} +- {:.3g}'.format(c_best_array.mean(), c_best_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "c_best = c_best_array.mean()\n",
    "Kernel_2 = Kernel(c=c_best, p=2)\n",
    "Pegasos_kernel_quadratic_CV = Pegasos_kernel(kernel=Kernel_2,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_quadratic_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubic example, the procedure is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "c_best_list = []\n",
    "l_best_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "\n",
    "    best_val = 1E8\n",
    "    best_l = 0\n",
    "    best_c = 0\n",
    "    for c in [0, 1, 5, 10, 50, 100]:\n",
    "        Kernel_3 = Kernel(c=c, p=3)\n",
    "        for l in [1, 5, 10, 50, 100, 1000]:\n",
    "            Pegasos_reg_kernel_3 = Pegasos_kernel(kernel=Kernel_3, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_3.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_3 = Pegasos_reg_kernel_3.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_3 = Pegasos_reg_kernel_3.MSE(X_val_, y_val_)\n",
    "            #print('Train:', MSE_Pegasos_train_2)\n",
    "            #print('Val:', MSE_Pegasos_val_2)\n",
    "            if MSE_Pegasos_val_3 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_3        \n",
    "                best_c = c\n",
    "    c_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    l_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    for c in c_search:\n",
    "        Kernel_2 = Kernel(c=c, p=2)\n",
    "        for l in l_search:\n",
    "            Pegasos_reg_kernel_2 = Pegasos_kernel(kernel=Kernel_2, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_2.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_2 = Pegasos_reg_kernel_2.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_2 = Pegasos_reg_kernel_2.MSE(X_val_, y_val_)\n",
    "            #print('Train:', MSE_Pegasos_train_2)\n",
    "            #print('Val:', MSE_Pegasos_val_2)\n",
    "            if MSE_Pegasos_val_2 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_2        \n",
    "                best_c = c\n",
    "    c_best_list.append(best_c)\n",
    "    l_best_list.append(best_l)\n",
    "    MSE_list.append(MSE_min(l_opt))\n",
    "\n",
    "    MSE_mean += best_val / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | c = {} | lambda = {:.2g}'.format(n_val+1, n_bags, best_val, best_c, best_l))\n",
    "best_l_array = np.array(l_best_list)\n",
    "c_best_array = np.array(c_best_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, best_l_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "c_best = c_best_array.mean()\n",
    "Kernel_3 = Kernel(c=c_best, p=3)\n",
    "Pegasos_kernel_kubic_CV = Pegasos_kernel(kernel=Kernel_3,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_kubic_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model is fitted. \n",
    "This model is the base line for measuring the models' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_sklearn = np.dot(X_test, lin_reg.coef_) + lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights and bias' of the *Linear Regression* and *linear Pegasos* are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "compare_weights = pd.DataFrame()\n",
    "compare_weights['Name'] = ['Bias'] + list(column_names[:-1])\n",
    "compare_weights['Linear Regression'] = np.append(lin_reg.intercept_, lin_reg.coef_)\n",
    "compare_weights['Pegasos linear'] = np.append(Pegasos_linear_CV.theta_0, Pegasos_linear_CV.theta)\n",
    "pd.set_option('display.precision', 3)\n",
    "print(compare_weights.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) on the test data set is compared. In addition, the increase in MSE is referenced to the analytical solution of the *Linear Regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_compare = pd.Series(dtype=float)\n",
    "ARD_compare = pd.Series(dtype=float) \n",
    "MSE_compare['Sklearn'] = Metric_regression().fun_MSE(y_test, y_test_sklearn)\n",
    "MSE_compare['Pegasos (linear)'] = Pegasos_linear_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - linear)'] = Pegasos_kernel_linear_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - quadratic)'] = Pegasos_kernel_quadratic_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - kubic)'] = Pegasos_kernel_kubic_CV.MSE(X_test, y_test)\n",
    "\n",
    "ARD_compare['Sklearn'] = 0\n",
    "ARD_compare['Pegasos (linear)'] = -(MSE_compare['Pegasos (linear)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - linear)'] = -(MSE_compare['Pegasos (Kernel - linear)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - quadratic)'] = -(MSE_compare['Pegasos (Kernel - quadratic)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - kubic)'] = -(MSE_compare['Pegasos (Kernel - kubic)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "\n",
    "MSE_DF = MSE_compare.to_frame(name='MSE')\n",
    "ARD_DF = ARD_compare.to_frame(name='Deviation / %')\n",
    "performance_DF = pd.concat([ARD_DF, MSE_DF], axis=1)\n",
    "print(performance_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is a measurement for the future predictive performance. \n",
    "Interestingly, the the *linear Pegasos* and the *Pegasos (Kernel - linear)* are outperformed by the Linear Regression (Sklearn). \n",
    "\n",
    "The error is composed of the bias, variance of the model, and noise of the data.  \n",
    "For evaluation the cause of the poor performance, the validation error is plotted as a function of the number of trainings data, while keeping the validation constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = []\n",
    "MSE_val = []\n",
    "train_samples = []\n",
    "Pegasos_linear_CV = Pegasos_regression(regularization=l_best_linear,\n",
    "                             epoch_max=epoch_max,\n",
    "                             epsilon=1E-8,\n",
    "                             verbose=False)\n",
    "\n",
    "n = X_train.shape[0]\n",
    "split_fraction = 0.8\n",
    "n_split = int(n * split_fraction)\n",
    "X_val_ = X_train[n_split:,:]\n",
    "y_val_ = y_train[n_split:]\n",
    "\n",
    "lin_reg_sub = LinearRegression()\n",
    "lin_reg_sub.fit(X_train[:n_split,:], y_train[:n_split])\n",
    "y_val = np.dot(X_val_, lin_reg.coef_) + lin_reg.intercept_\n",
    "MSE_epsilon = Metric_regression().fun_MSE(y_val, y_val_)\n",
    "\n",
    "n_start = 10\n",
    "for n_sample in tqdm(range(n_start, n_split)):\n",
    "    train_samples.append(n_sample)\n",
    "    X_train_sub = X_train[:n_sample,:]\n",
    "    y_train_sub = y_train[:n_sample]\n",
    "    \n",
    "    Pegasos_linear_CV.fit(X_train_sub, y_train_sub)\n",
    "    MSE_train.append(Pegasos_linear_CV.MSE(X_train_sub, y_train_sub))\n",
    "    MSE_val.append(Pegasos_linear_CV.MSE(X_val_, y_val_))\n",
    "   \n",
    "plt.plot(train_samples, [MSE_epsilon for n in range(n_start, n_split)])\n",
    "plt.plot(train_samples, MSE_train)\n",
    "plt.plot(train_samples, MSE_val)\n",
    "plt.xlim(0, n_split)\n",
    "plt.xlabel('$n_\\mathrm{{train}}$ / -')\n",
    "plt.ylabel('MSE$\\mathrm{_{val}}$')\n",
    "plt.legend(['Linear Regression','Training', 'Testing'])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training and testing error are both above the *Linear Regression's*. \n",
    "Therefore, the model's capacity is not high enough.\n",
    "The capacity is increased with the qudratic and kubic kernels resulting in decreasing validaiton errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
