{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) with Pegasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important namespaces are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical operation\n",
    "import pandas as pd #tabular data\n",
    "from tqdm import tqdm #progress bars\n",
    "import matplotlib.pyplot as plt #figures\n",
    "from sklearn.linear_model import LinearRegression #linear regression benchmark\n",
    "import sys #System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custum modules, consisting of among others the Pegasos algorithm, are imported. \n",
    "Therefore, a relative path is appended to the system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'Modules/')\n",
    "from Evaluation_Metric import Metric_regression\n",
    "from Cross_validation import preparation_cross_validation\n",
    "golden_section_search = __import__('20220716_Golden_Section_Search').golden_section_search\n",
    "from Primal_Pegasos import Pegasos_regression\n",
    "Pegasos_kernel = __import__('Kernel_Pegasos').Pegasos_kernel_regression\n",
    "Kernel_p = __import__('Kernel_Pegasos').Kernel_polynomial   \n",
    "Kernel_rbf = __import__('Kernel_Pegasos').RBF   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **boston house prices** dataset is imported. \n",
    "The dataset is commonly used for comparison regression algorithm.\n",
    "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.\n",
    "\n",
    "http://lib.stat.cmu.edu/datasets/boston (accessed on 26th July 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non numeric values are removed from this dataset. \n",
    "Each row, containing NaN, is removed ensuring only numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan = np.isnan(data)\n",
    "X_nan = X_nan.sum(axis=1)\n",
    "X_no_nan = X_nan == 0\n",
    "X = data[X_no_nan,:]\n",
    "y = target[X_no_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix is centered around 0 with a standard deviation of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X - X.mean(axis=0)\n",
    "X = X / X.var(axis=0)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is randomly splitted in trainings and testing data. \n",
    "The algorthm is trained and the hyperparameter are adjusted based on the trainings data. \n",
    "The final performance evaluation is done with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = X.shape[0]\n",
    "split_fraction = 0.8\n",
    "n_random = np.random.permutation(n)\n",
    "n_train = n_random[:int(n*split_fraction)]\n",
    "n_test = n_random[int(n*split_fraction):]\n",
    "\n",
    "X_train = X[n_train,:]\n",
    "y_train = y[n_train]\n",
    "\n",
    "X_test = X[n_test,:]\n",
    "y_test =  y[n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainings data set is splitted into $n$ bags. \n",
    "For randomization the modul numpy is applied. \n",
    "The optimal regularisation parameter $\\lambda$ is searched such that the validation error is minimized. \n",
    "Therefore, the models are fitted on $n - 1$ bags and the performance is evaluated on $1$ bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bags = 10\n",
    "np.random.seed(42)\n",
    "bags_list = preparation_cross_validation(X_train, y_train, n_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is approximated with the validaiton error. \n",
    "Therefore, the function *MSE_l* fits the linear Pegasos models to the trainings data and return the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_max_diagram = 3\n",
    "def MSE_l (l, Pegasos_regression, epoch_max, epsilon, X_train, y_train, X_val, y_val):\n",
    "    Pegasos = Pegasos_regression(regularization=l,\n",
    "                                 epoch_max=epoch_max,\n",
    "                                 epsilon=epsilon,\n",
    "                                 verbose=False)\n",
    "    Pegasos.fit(X_train, y_train)\n",
    "    MSE_ = Pegasos.MSE(X_val, y_val)\n",
    "    return (MSE_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on the validation set is unimodal with exactly one minimum. \n",
    "The $n$ cross validation sets are plotted as a function of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_list = ['$n\\mathrm{_{bag}}$ = ' + str(i+1) for i in range(n_bags)]\n",
    "l_array = np.logspace(-5, 2, 100)\n",
    "for n_val in tqdm(range (n_bags)):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_min = lambda l: MSE_l(l, \n",
    "                              Pegasos_regression=Pegasos_regression, \n",
    "                              epoch_max=epoch_max_diagram, \n",
    "                              epsilon=1E-8, \n",
    "                              X_train=X_train_, \n",
    "                              y_train=y_train_, \n",
    "                              X_val=X_val_, \n",
    "                              y_val=y_val_)\n",
    "    MSE_min_vec = np.vectorize(MSE_min)\n",
    "    plt.plot(l_array, MSE_min_vec(l_array))\n",
    "\n",
    "plt.title('Epoch$\\mathrm{_{max}}$ = ' + '{:.0f}'.format(epoch_max_diagram))\n",
    "plt.xlabel('$\\lambda$ / -')\n",
    "plt.xscale('log')\n",
    "plt.xlim(1E-5, 10000)\n",
    "plt.ylabel('MEDV$\\mathrm{_{val}}$')\n",
    "plt.legend(legend_list, loc='upper right', fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optima $\\lambda$ are found with the golden section search. \n",
    "The golden section search finds the mimimum in a given intervall, for strictly unimodal functions. \n",
    "Thereafter, the whole trainings set is fitted with the average $\\lambda$ of the cross validation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9432c7c27fdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                               X_val=X_val_, y_val=y_val_)\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0ml_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgolden_section_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1E-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1E-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0ml_opt_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mMSE_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE_min\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\2022\\5_Python\\000_Git_Hub\\Pegasos\\Modules\\20220716_Golden_Section_Search.py\u001b[0m in \u001b[0;36mgolden_section_search\u001b[1;34m(function, x_min, x_max, eps)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_min\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlambda_golden\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0my_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0my_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_max\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-9432c7c27fdc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(l)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0my_train_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     MSE_min = lambda l: MSE_l(l, \n\u001b[0m\u001b[0;32m     18\u001b[0m                               \u001b[0mPegasos_regression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPegasos_regression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                               \u001b[0mepoch_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0a56a8929dee>\u001b[0m in \u001b[0;36mMSE_l\u001b[1;34m(l, Pegasos_regression, epoch_max, epsilon, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                  verbose=False)\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mPegasos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mMSE_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPegasos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mMSE_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\2022\\5_Python\\000_Git_Hub\\Pegasos\\Modules\\Primal_Pegasos.py\u001b[0m in \u001b[0;36mfit_silence\u001b[1;34m(self, feature_matrix, labels)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\2022\\5_Python\\000_Git_Hub\\Pegasos\\Modules\\Primal_Pegasos.py\u001b[0m in \u001b[0;36msingle_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_datapoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\2022\\5_Python\\000_Git_Hub\\Pegasos\\Modules\\Primal_Pegasos.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, feature_matrix)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\2022\\5_Python\\000_Git_Hub\\Pegasos\\Modules\\Primal_Pegasos.py\u001b[0m in \u001b[0;36mdecision_boundary\u001b[1;34m(self, feature_matrix)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         '''\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_max = 3\n",
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "l_opt_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_min = lambda l: MSE_l(l, \n",
    "                              Pegasos_regression=Pegasos_regression,\n",
    "                              epoch_max=epoch_max, \n",
    "                              epsilon=1E-8, \n",
    "                              X_train=X_train_, y_train=y_train_, \n",
    "                              X_val=X_val_, y_val=y_val_)\n",
    "    \n",
    "    l_opt = golden_section_search(MSE_min, 1E-3, 10, 1E-3)\n",
    "    l_opt_list.append(l_opt)\n",
    "    MSE_list.append(MSE_min(l_opt))\n",
    "    MSE_mean += MSE_min(l_opt) / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2g} | lambda = {:.2g}'.format(n_val+1, n_bags, MSE_min(l_opt), l_opt))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_opt_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best_linear = best_l_array.mean()\n",
    "Pegasos_linear_CV = Pegasos_regression(regularization=l_best_linear,\n",
    "                             epoch_max=epoch_max,\n",
    "                             epsilon=1E-8)\n",
    "Pegasos_linear_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is approximated with the validaiton error. \n",
    "Therefore, the function *MSE_kernel* fits the kernalized Pegasos models to the trainings data and return the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_kernel (l, Pegasos, Kernel, epoch_max, epsilon, X_train, y_train, X_val, y_val):\n",
    "    Pegasos_ = Pegasos(kernel=Kernel,\n",
    "                              regularization=l,\n",
    "                              epoch_max=epoch_max,\n",
    "                              epsilon=epsilon,\n",
    "                              verbose=False)\n",
    "    Pegasos_.fit(X_train, y_train)\n",
    "    MSE_ = Pegasos_.MSE(X_val, y_val)\n",
    "    return (MSE_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal $\\lambda$ are found for the linear kernalized Pegasos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "Kernel_linear = Kernel_p(c=0, p=1)\n",
    "l_opt_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    MSE_kernel_lambda = lambda l: MSE_kernel(l,\n",
    "                                             Pegasos=Pegasos_kernel, \n",
    "                                             Kernel=Kernel_linear,  \n",
    "                                             epoch_max=epoch_max, \n",
    "                                             epsilon=1E-8, \n",
    "                                             X_train=X_train_, \n",
    "                                             y_train=y_train_, \n",
    "                                             X_val=X_val_, \n",
    "                                             y_val=y_val_)\n",
    "    \n",
    "    l_opt = golden_section_search(MSE_kernel_lambda, 1E-5, 100, 1E-3)\n",
    "    l_opt_list.append(l_opt)\n",
    "    MSE_list.append(MSE_kernel_lambda(l_opt))\n",
    "    MSE_mean += MSE_kernel_lambda(l_opt) / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | lambda = {:.2g}'.format(n_val+1, n_bags, MSE_min(l_opt), l_opt))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_opt_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "Pegasos_kernel_linear_CV = Pegasos_kernel(kernel=Kernel_linear,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_linear_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal $c$ and $\\lambda$ are aproximated with the grid search. \n",
    "Higher $c$ gives more weight to the features with lower dimensions. \n",
    "Thus, $c$ and $\\lambda$ are reducing the complexity of the model.\n",
    "\n",
    "First, order of magnitude of the parameter $c$ and $\\lambda$ is searched. Thereafter, the search repeated with smaller step sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "c_best_list = []\n",
    "l_best_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "\n",
    "    best_val = 1E8\n",
    "    best_l = 0\n",
    "    best_c = 0\n",
    "    for c in [0, 0.5, 1, 5, 10, 50, 100]:\n",
    "        Kernel_2 = Kernel_p(c=c, p=2)\n",
    "        for l in [1E-5, 1E-4, 1E-3, 1E-2, 0.1, 1, 10]:\n",
    "            Pegasos_reg_kernel_2 = Pegasos_kernel(kernel=Kernel_2, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_2.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_val_2 = Pegasos_reg_kernel_2.MSE(X_val_, y_val_)\n",
    "            if MSE_Pegasos_val_2 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_2        \n",
    "                best_c = c\n",
    "                \n",
    "    c_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    l_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    for c in c_search:\n",
    "        Kernel_2 = Kernel_p(c=c, p=2)\n",
    "        for l in l_search:\n",
    "            Pegasos_reg_kernel_2 = Pegasos_kernel(kernel=Kernel_2, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_2.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_val_2 = Pegasos_reg_kernel_2.MSE(X_val_, y_val_)\n",
    "            if MSE_Pegasos_val_2 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_2        \n",
    "                best_c = c\n",
    "    \n",
    "    c_best_list.append(best_c)\n",
    "    l_best_list.append(best_l)\n",
    "    MSE_list.append(best_val)\n",
    "\n",
    "    MSE_mean += best_val / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | c = {} | lambda = {:.2g}'.format(n_val+1, n_bags, best_val, best_c, best_l))\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_best_list)\n",
    "c_best_array = np.array(c_best_list)\n",
    "print('MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "print('Best c = {:.3g} +- {:.3g}'.format(c_best_array.mean(), c_best_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "c_best = c_best_array.mean()\n",
    "Kernel_2 = Kernel_p(c=c_best, p=2)\n",
    "Pegasos_kernel_quadratic_CV = Pegasos_kernel(kernel=Kernel_2,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_quadratic_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubic example, the procedure is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "c_best_list = []\n",
    "l_best_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "\n",
    "    best_val = 1E8\n",
    "    best_l = 0\n",
    "    best_c = 0\n",
    "    for c in [0, 0.5, 1, 5, 10, 50, 100]:\n",
    "        Kernel_3 = Kernel_p(c=c, p=3)\n",
    "        for l in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "            Pegasos_reg_kernel_3 = Pegasos_kernel(kernel=Kernel_3, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_3.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_val_3 = Pegasos_reg_kernel_3.MSE(X_val_, y_val_)\n",
    "            if MSE_Pegasos_val_3 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_3        \n",
    "                best_c = c\n",
    "    c_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    l_search = [best_c * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    for c in c_search:\n",
    "        Kernel_3 = Kernel_p(c=c, p=3)\n",
    "        for l in l_search:\n",
    "            Pegasos_reg_kernel_3 = Pegasos_kernel(kernel=Kernel_3, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_kernel_3.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_3 = Pegasos_reg_kernel_3.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_3 = Pegasos_reg_kernel_3.MSE(X_val_, y_val_)\n",
    "            if MSE_Pegasos_val_3 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_3        \n",
    "                best_c = c\n",
    "    c_best_list.append(best_c)\n",
    "    l_best_list.append(best_l)\n",
    "    MSE_list.append(best_val)\n",
    "\n",
    "    MSE_mean += best_val / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | c = {} | lambda = {:.2g}'.format(n_val+1, n_bags, best_val, best_c, best_l))\n",
    "\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_best_list)\n",
    "c_best_array = np.array(c_best_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "print('Best c = {:.3g} +- {:.3g}'.format(c_best_array.mean(), c_best_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "c_best = c_best_array.mean()\n",
    "Kernel_3 = Kernel_p(c=c_best, p=3)\n",
    "Pegasos_kernel_kubic_CV = Pegasos_kernel(kernel=Kernel_3,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_kubic_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (on validation set 1/10) = 9.22 | gamma = 0.1 | lambda = 0.0011\n"
     ]
    }
   ],
   "source": [
    "MSE_mean = 0\n",
    "MSE_list = []\n",
    "gamma_best_list = []\n",
    "l_best_list = []\n",
    "for n_val in range (n_bags):\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    X_val_ = np.array(bags_list[n_val].x)\n",
    "    y_val_ =  np.array(bags_list[n_val].y)\n",
    "    for n in range (n_bags):\n",
    "        if n_val != n:\n",
    "            X_train_ += bags_list[n].x\n",
    "            y_train_ += bags_list[n].y\n",
    "    X_train_ = np.array(X_train_)\n",
    "    y_train_ = np.array(y_train_)\n",
    "\n",
    "    best_val = 1E8\n",
    "    best_l = 0\n",
    "    best_gamma = 0\n",
    "    for gamma in [0.01, 0.1, 1, 10, 100]:\n",
    "        Kernel_ = Kernel_rbf(gamma=gamma)\n",
    "        for l in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "            Pegasos_reg_rbf = Pegasos_kernel(kernel=Kernel_, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_rbf.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_train_4 = Pegasos_reg_rbf.MSE(X_train, y_train)\n",
    "            MSE_Pegasos_val_4 = Pegasos_reg_rbf.MSE(X_val_, y_val_)\n",
    "            if MSE_Pegasos_val_4 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_4        \n",
    "                best_gamma = gamma\n",
    "                \n",
    "    gamma_search = [best_gamma * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    l_search = [best_l * n for n in [1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    for gamma in gamma_search:\n",
    "        Kernel_ = Kernel_rbf(gamma=gamma)\n",
    "        for l in l_search:\n",
    "            Pegasos_reg_rbf = Pegasos_kernel(kernel=Kernel_, \n",
    "                                                regularization=l, \n",
    "                                                epoch_max=epoch_max, \n",
    "                                                epsilon=1E-8,\n",
    "                                                verbose=False)\n",
    "            Pegasos_reg_rbf.fit(X_train_, y_train_)\n",
    "            MSE_Pegasos_val_4 = Pegasos_reg_rbf.MSE(X_val_, y_val_)\n",
    "\n",
    "            if MSE_Pegasos_val_4 < best_val:\n",
    "                best_l = l\n",
    "                best_val = MSE_Pegasos_val_4        \n",
    "                best_gamma = gamma\n",
    "                \n",
    "    gamma_best_list.append(best_gamma)\n",
    "    l_best_list.append(best_l)\n",
    "    MSE_list.append(best_val)\n",
    "\n",
    "    MSE_mean += best_val / n_bags \n",
    "    print('MSE (on validation set {}/{}) = {:.2f} | gamma = {} | lambda = {:.2g}'.format(n_val+1, n_bags, best_val, best_gamma, best_l))\n",
    "\n",
    "MSE_array = np.array(MSE_list)\n",
    "best_l_array = np.array(l_best_list)\n",
    "gamma_best_array = np.array(gamma_best_list)\n",
    "print('Mean MSE Cross Validation = {:.3g} +- {:.3g}'.format(MSE_mean, MSE_array.var(ddof=1)**0.5))\n",
    "print('Best lambda = {:.3g} +- {:.3g}'.format(best_l_array.mean(), best_l_array.var(ddof=1)**0.5))\n",
    "print('Best gamma = {:.3g} +- {:.3g}'.format(gamma_best_array.mean(), gamma_best_array.var(ddof=1)**0.5))\n",
    "\n",
    "l_best = best_l_array.mean()\n",
    "gamma_best = gamma_best_array.mean()\n",
    "Kernel_ = Kernel_rbf(gamma=gamma)\n",
    "Pegasos_kernel_rbf_CV = Pegasos_kernel(kernel=Kernel_,\n",
    "                                          regularization=l_best,\n",
    "                                          epoch_max=epoch_max,\n",
    "                                          epsilon=1E-8,\n",
    "                                           )\n",
    "Pegasos_kernel_rbf_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model is fitted. \n",
    "This model is the base line for measuring the models' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_sklearn = np.dot(X_test, lin_reg.coef_) + lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights and bias' of the *Linear Regression* and *linear Pegasos* are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "compare_weights = pd.DataFrame()\n",
    "compare_weights['Name'] = ['Bias'] + list(column_names[:-1])\n",
    "compare_weights['Linear Regression'] = np.append(lin_reg.intercept_, lin_reg.coef_)\n",
    "compare_weights['Pegasos linear'] = np.append(Pegasos_linear_CV.theta_0, Pegasos_linear_CV.theta)\n",
    "pd.set_option('display.precision', 3)\n",
    "print(compare_weights.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) on the test data set is compared. In addition, the increase in MSE is referenced to the analytical solution of the *Linear Regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_compare = pd.Series(dtype=float)\n",
    "ARD_compare = pd.Series(dtype=float) \n",
    "MSE_compare['Sklearn'] = Metric_regression().fun_MSE(y_test, y_test_sklearn)\n",
    "MSE_compare['Pegasos (linear)'] = Pegasos_linear_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - linear)'] = Pegasos_kernel_linear_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - quadratic)'] = Pegasos_kernel_quadratic_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - kubic)'] = Pegasos_kernel_kubic_CV.MSE(X_test, y_test)\n",
    "MSE_compare['Pegasos (Kernel - rbf)']  = Pegasos_kernel_rbf_CV.MSE(X_test, y_test)\n",
    "\n",
    "ARD_compare['Sklearn'] = 0\n",
    "ARD_compare['Pegasos (linear)'] = -(MSE_compare['Pegasos (linear)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - linear)'] = -(MSE_compare['Pegasos (Kernel - linear)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - quadratic)'] = -(MSE_compare['Pegasos (Kernel - quadratic)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - kubic)'] = -(MSE_compare['Pegasos (Kernel - kubic)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "ARD_compare['Pegasos (Kernel - rbf)'] = -(MSE_compare['Pegasos (Kernel - rbf)'] - MSE_compare['Sklearn'])  / MSE_compare['Sklearn']*100\n",
    "\n",
    "MSE_DF = MSE_compare.to_frame(name='MSE')\n",
    "ARD_DF = ARD_compare.to_frame(name='Deviation / %')\n",
    "performance_DF = pd.concat([ARD_DF, MSE_DF], axis=1)\n",
    "print(performance_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is a measurement for the future predictive performance. \n",
    "Interestingly, the the *linear Pegasos* and the *Pegasos (Kernel - linear)* are outperformed by the Linear Regression (Sklearn). \n",
    "\n",
    "The error is composed of the bias, variance of the model, and noise of the data.  \n",
    "For evaluation the cause of the poor performance, the validation error is plotted as a function of the number of trainings data, while keeping the validation constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = []\n",
    "MSE_val = []\n",
    "train_samples = []\n",
    "Pegasos_linear_CV = Pegasos_regression(regularization=l_best_linear,\n",
    "                             epoch_max=epoch_max,\n",
    "                             epsilon=1E-8,\n",
    "                             verbose=False)\n",
    "\n",
    "n = X_train.shape[0]\n",
    "split_fraction = 0.8\n",
    "n_split = int(n * split_fraction)\n",
    "X_val_ = X_train[n_split:,:]\n",
    "y_val_ = y_train[n_split:]\n",
    "\n",
    "lin_reg_sub = LinearRegression()\n",
    "lin_reg_sub.fit(X_train[:n_split,:], y_train[:n_split])\n",
    "y_val = np.dot(X_val_, lin_reg.coef_) + lin_reg.intercept_\n",
    "MSE_epsilon = Metric_regression().fun_MSE(y_val, y_val_)\n",
    "\n",
    "n_start = 10\n",
    "for n_sample in tqdm(range(n_start, n_split)):\n",
    "    train_samples.append(n_sample)\n",
    "    X_train_sub = X_train[:n_sample,:]\n",
    "    y_train_sub = y_train[:n_sample]\n",
    "    \n",
    "    Pegasos_linear_CV.fit(X_train_sub, y_train_sub)\n",
    "    MSE_train.append(Pegasos_linear_CV.MSE(X_train_sub, y_train_sub))\n",
    "    MSE_val.append(Pegasos_linear_CV.MSE(X_val_, y_val_))\n",
    "   \n",
    "plt.plot(train_samples, [MSE_epsilon for n in range(n_start, n_split)])\n",
    "plt.plot(train_samples, MSE_train)\n",
    "plt.plot(train_samples, MSE_val)\n",
    "plt.xlim(0, n_split)\n",
    "plt.xlabel('$n_\\mathrm{{train}}$ / -')\n",
    "plt.ylabel('MSE$\\mathrm{_{val}}$')\n",
    "plt.legend(['Linear Regression','Training', 'Testing'])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training and testing error are both above the *Linear Regression's*. \n",
    "Therefore, the model's capacity is not high enough.\n",
    "The capacity is increased with the qudratic and kubic kernels resulting in decreasing validaiton errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
